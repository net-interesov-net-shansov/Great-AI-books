# Глава 4 - начало работы с нейронными сетями для задач классификации
### Глоссарий классификации и регресии:
- **Обзазец (sample) или вход** - одни экземпляр данных поступающих в модель
- **Прогноз или выход (prediction)** - результат работы модели
- **Цель (target)** - идеальный прогнох модели
- **Величина потерь (loss value)** - мера расстояния между прогнозом и целью
- **Классы** - набор меток в задаче классификации, доступных для выбора. _Например - при классификации изображений с кошками и собаками 
доступны два класса: кошка и собака_
- **Метка (label)** - конкретный экземпляр класса в задаче классификации. _Например - изображение №123 аннотировано как 
принадлежащее классу "собака" => собака является меткойизображения №123_
- **Эталоны (ground-truth) или аннотации** - все цели для набора данных, собираются людьми вручную
- **Бинарная классификация** - задача классификации, которая разделяет входные данные на две взаимоисключающие категории
- **Многоклассовая классификация (multiclass classification)** - задача классификации, которая разделяет входные данные на более чем две взаимоисключающие категории. 
_(классификация рукописных цифр)_
- **Многозначная/нечёткая классификация (multilabel classification)** - задача классификации, в которой каждому входному образцу можно присвоить несколько меток
- **Скалярная регрессия (scalar regression)** - задача, в которой цель является скалярным числом, лежащим на непрерывной числовой прямой. 
_Пример - прогнозирование цен на жильё: разные цены из непрерывного диапозона_
- **Векторная регрессия (vector regression)** - задача, в которой цель является набором чисел, лежаших на непрерывной числовой прямой. 
_Пример - регрессия по нескольким значениям координат прямоугольника, ограничивающего изображение_
- **Пакет и мини-пакет (batch/mini-batch)** - набор образцов (обычноот 8 до 128), обрабатываемых моделью одновременно. 
Число образцов часто является степенью двойки, для более эффективного использования памяти GPU. 
В процессе обучения, один пакет используется в градиентном спуске для вычислния одного изменения весов

### Суть главы №4.1
- Исходные данные необходимо подвергать предварительной обработке. 
Последовательности слов можно преобразовать в бинарные векторы (сущ. и другие варианты)
- Стек слоёв Dense с функцией активации relu способен решить широкий спектр задач.
Данная комбинация используется довольно часто
- В задаче бинарной классификации в конце модели должен находится слой Dense с одним 
нейроном и функцией активации sigmoid; Результатом работы сети должно стать скалярное 
значение в диапозоне от 0 до 1, представляющее вероятность.
- Со скалярным результатом, получаемой с помощью сигмоидной функции,
 рекомендуется использовать функцию потерь binary_crossentropy.
- В общем случае, оптимизатор rmsprop является наиболее подходящим выбором для любого типа задач
- По мере обучения на обучающих данных, в какой-то момент, нейронные сети начинают переобучаться,
демонстрируя ухудшение на новых данных. Нужно котролировать качество работы сети на тесовых данных не из набора

### Суть главы 4.2
- При классификации образцов данных по классам, модель должна завершаться слоем Dence размера _N_, где _N_ - кол-во классов
- В задаче однозначной многоклассовой классификации заключительный слой модели должен иметь функцию активации _softmax_, чтобы выводить распределение вероятностей между _N_ классами
- В задаче однозначной многоклассовой классификации следует использовать функцию потерь _categorical_crossentropy_. Она минимизирует расстояние между распределениями вероятностей, выводимыми моделью, и истиными распределениями целей
- Метки монгоклассовой классфикации можно обработать двумя способами:
    - кодировать из с помощью метода кодирования категорий (прямое кодирование), с функцией потерь _categorical_crossentropy_
    - кодировать их как целые числа (```x_train = np.array(train_labels)```) с функцией потерь _spare_categorical_crossentropy_
- При классификации по _N_ категорий, нужно избегать применения слоёв с недостаточно большим количеством измерений

### Суть главы 4.3
- Регрессия выполняется с иными функциями потерь, нежели классификация. Часто используется функция потерь, вычисляющая среднеквадратичную ошибку **_(mean squared error, MSE)_**
- Также, используются другие метрики оценки - понятие точности неприменимо для регрессии, поэтому оценка происодит по **средней абсолютной ошибке _(mean absolute error, MAE)_**
- Если признаки образцов имеют значения из разных диапозонов, их необходимо предварительно масштабировать до диапозона от -1 до 1
- При небольшом наборе данных, оценка качества модели производится с помощью **_метода перекрёснтной проверки по К блокам_**
- При небольшом объёме данных рекомендуется использовать маленьке модели с небольшим количесвом промежуочных слоёв (обычно 1 или 2), для избежания переобучения

## Выжимка из 4 _-ой_ главы
- Самые распространённые задачи ML на векторных данных - **бинарная классификация, многоклассовая классификация и скалярная регрессия**
- Исходные данные подвергаются предварительной обработке
- Если данные имеют признаки с разными диапозонами - данные предварительно масштабируются
- Необходимо следить, на какой итерации проявляется переобучение и заканчивать обучение на этой итерации, вопрос эффективности далее остаётся за конфигурацией сети, а не за количеством итерций обучения
- При большом кол-ве категорий в обучающих данных, нужно стараться не ограничивать размерность слоёв слишком сильно, иначе это приведёт к потере информации